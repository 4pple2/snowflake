from snowflake.snowpark.context import get_active_session
from snowflake.snowpark.functions import sum, col
from snowflake.snowpark.session import Session
from pandas.plotting import table
from config_s3 import settings
#ì‹œê°í™”
import altair as alt
import streamlit as st
import pandas as pd
import config
import dataframe_image as dfi 
import matplotlib.pyplot as plt

import os
import sys
import íŒŒì´ì¬_í…ŒìŠ¤íŠ¸

import boto3
import json
from datetime import datetime 
st.set_page_config(layout="wide")
empty1,con1,empty2 = st.columns([0.3,1.0,0.3])

# snowflake ì—°ê²°
def Create_session_object() -> Session:
   _conn_params = {
      "account": config.conn_params["account"],
      "user": config.conn_params["user"],
      "password": config.conn_params["password"],
      "role": config.conn_params["role"],
      "warehouse": config.conn_params["warehouse"],
      "database": config.conn_params["database"],
      "schema" : "CJ_TEST"
   }

   session = Session.builder.configs(_conn_params).create()
   print(session.sql('select current_warehouse(), current_database(), current_schema()').collect())
   return session
# s3_ boto3 í™˜ê²½ì„¤ì •
ACCESS_KEY = 'AKIAY2WQZ36SOZD5FFOY'
SECRET_KEY = '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'
bucket = 'test4streamlit'
file_name = 's3_test_{}{:02d}{:02d}{:02d}'.format(datetime.today().year, datetime.today().month, datetime.today().day, datetime.today().second)

#  
def upload_file_s3(bucket,file_name,file):
    s3 = boto3.client('s3',aws_access_key_id = ACCESS_KEY, aws_secret_access_key=SECRET_KEY)
    encode_file = json.dumps(file,indent=4, ensure_ascii=False)
    
    try:
        s3.put_object(Bucket=bucket,Key=file_name, Body=encode_file)
        return True
    except:
                return False

# ì¹¼ëŸ¼ëª… ë¶ˆëŸ¬ì˜¤ê¸°
def column_name():
    sql = f"""SELECT *
              FROM penta.CJ_TEST."VW_ì œí’ˆ_ì›”ë³„íŒë§¤_ì•„ì´í…œ" where 1=2 limit 1;  
               """
    created_dataframe = session.sql(sql)
    queried_data = created_dataframe.to_pandas()
    
   
    return queried_data.columns



# ì¹¼ëŸ¼ ê°’ ë¶ˆëŸ¬ì˜¤ê¸°
def column_data(filter_col):
    sql = f"""SELECT "{filter_col}"
              FROM penta.CJ_TEST."VW_ì œí’ˆ_ì›”ë³„íŒë§¤_ì•„ì´í…œ" group by "{filter_col}" ORDER by "{filter_col}" limit 10 ;
               """
    
    created_dataframe = session.sql(sql)
    queried_data = created_dataframe.to_pandas()
    
    return queried_data
    

# í•„í„° êµ¬í˜„
def filter_data(filter_dict):
    
    sql = f"""SELECT *
      FROM penta.CJ_TEST."VW_ì œí’ˆ_ì›”ë³„íŒë§¤_ì•„ì´í…œ"
      WHERE 1=1 
    """
  
    for key, value in filter_dict.items(): 
        
        value_str = ', '.join([f"'{k}'" for k in value])
        
        if value_str == '':
         break
        else:
            sql += f""" and "{key}" NOT IN ({value_str})"""
    
    sql += """ LIMIT 100;"""                                             # í…Œì´ë¸” ê°œìˆ˜ ì„¤ì •

    
    created_dataframe = session.sql(sql)
    queried_data = created_dataframe.to_pandas()

    return queried_data


# ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€ í•¨ìˆ˜
def add_filter_to_dict(filter_dict, filter_name, filters):              # ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€
    filter_dict[filter_name] = filters
    
# ë©”ì¸ í•¨ìˆ˜
def main(select_filters):

    filter_dict = {}                                                    # ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    columns = ''                                                        # ê¶Œì—­ ìª¼ê°œê¸°ë¥¼ ìœ„í•œ ì´ˆê¸°í™”

    if len(select_filters) > 0:                                         # StreamlitAPIException ë°©ì§€í•˜ê¸° ìœ„í•œ ifë¬¸
        columns = st.columns(len(select_filters))

        
    for i, filter_col in enumerate(columns, start=0):                   # ì„¤ëª…ì„ ìœ„í•´ì„œ iê°’ì„ ì¶”ê°€í–ˆë‹¤.
        filters = filter_col.multiselect(f'{select_filters[i]} í•„í„°', column_data(select_filters[i])) # filters => ë¦¬ìŠ¤íŠ¸ë¡œ ìƒì„±
        add_filter_to_dict(filter_dict, select_filters[i], filters)
        
    data_filtered = filter_data(filter_dict)                            # st.writeí•˜ë©´ í‘œ ì¶”ì¶œ

    if len(select_rows) == 0:
        pdf1 = data_filtered
        return pdf1
    else:
        pdf1 = pd.pivot_table(data_filtered, index =select_columns,
                                columns=select_rows,
                                values = select_value)   

        return pdf1
    
if __name__ == "__main__":
    session = Create_session_object()
    button_1 = st.button("pivot download")

    st.sidebar.markdown(f"# Main pageğŸˆ")   
    col1 , col2 = st.sidebar.columns(2)
    col3 , col4 = st.sidebar.columns(2)

    # ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥ë¨
    select_filters = col1.multiselect('í•„í„°',column_name())               # ì„ íƒí•œ ê°’ì´ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ì§„ë‹¤.
    select_rows = col2.multiselect('í–‰',column_name())
    select_columns = col3.multiselect('ì—´',column_name())
    select_value = col4.multiselect('ê°’',column_name())

    st.title("Snowflake Streamlit Pivot Table")
    pdf1 = main(select_filters)
    

    ###### ì‚¼ê°í˜• ì—ëŸ¬ ì—†ì• ê¸°
    # í”¼ë²— í…Œì´ë¸”ì— ë§Œë“¤ë–„ ë°œìƒí•˜ëŠ” ì—ëŸ¬ë¥¼ ìˆ˜ì •í•¨ -> ì°¨íŠ¸ì˜ ê°’ì„ ë¬¸ìì—´ë¡œ ë³€ê²½í–ˆë‹¤.
    pivot1 = pdf1.fillna('')
    pivot2 = pivot1.copy()
   
    for col in pivot1.columns:
        pivot2[col] = pivot2[col].astype(str)
    st.dataframe(pivot2)

    button_2 = st.button("plot_ download")



    ###### í”¼ë²— í…Œì´ë¸” jsonìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ + target tableì— jsonìœ¼ë¡œ ì ì¬
    if button_1 == True:
        result = pdf1.to_json(orient='index')
        parsed = json.loads(result)
        upload_file_s3(bucket, file_name + '.json', parsed)
    
        #íŒŒì´ì¬_í…ŒìŠ¤íŠ¸.download('wanthome','test4streamlit',file_name+'.json')
        sql = f"copy into target_table from @json_s3/{file_name}.json FILE_FORMAT = (TYPE = JSON)"
        session_sql = session.sql(sql)
        session_sql.show()


